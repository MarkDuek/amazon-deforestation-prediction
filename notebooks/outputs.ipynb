{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 4 random patches...\n",
      "\n",
      "ERROR: Predictions file not found at ../results/predictions.h5\n",
      "\n",
      "ðŸ“‹ To generate predictions, please follow these steps:\n",
      "   1. Train the model: python main.py\n",
      "   2. The model will save predictions during evaluation\n",
      "   3. Re-run this notebook to visualize the predictions\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Display random patches for Amazon deforestation prediction.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "from utils.amazon_plots import plot_prediction_patch\n",
    "\n",
    "def load_predictions_from_h5(h5_file_path):\n",
    "    \"\"\"Load predictions from HDF5 file.\n",
    "    \n",
    "    Args:\n",
    "        h5_file_path: Path to the predictions HDF5 file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (predictions, binary_predictions, targets, metadata)\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the predictions file doesn't exist\n",
    "        Exception: If there's an error loading the file\n",
    "    \"\"\"\n",
    "    if not Path(h5_file_path).exists():\n",
    "        raise FileNotFoundError(f\"Predictions file not found at {h5_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with h5py.File(h5_file_path, 'r') as f:\n",
    "            predictions = f['predictions'][:]  # type: ignore\n",
    "            binary_predictions = f['binary_predictions'][:]  # type: ignore\n",
    "            targets = f['targets'][:]  # type: ignore\n",
    "            \n",
    "            # Load metadata\n",
    "            metadata = {}\n",
    "            for key in f.attrs.keys():\n",
    "                metadata[key] = f.attrs[key]\n",
    "                \n",
    "            print(f\"Loaded predictions from {h5_file_path}\")\n",
    "            print(f\"Shape: {predictions.shape}\")  # type: ignore\n",
    "            print(f\"Metadata: {metadata}\")\n",
    "            \n",
    "            return predictions, binary_predictions, targets, metadata\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading predictions from {h5_file_path}: {e}\")\n",
    "\n",
    "def get_real_patch(predictions, binary_predictions, targets, patch_idx=None):\n",
    "    \"\"\"Get a real patch from loaded predictions.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Array of prediction probabilities\n",
    "        binary_predictions: Array of binary predictions\n",
    "        targets: Array of ground truth targets\n",
    "        patch_idx: Specific patch index to get (if None, random)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (prediction, binary_prediction, target)\n",
    "    \"\"\"\n",
    "    if patch_idx is None:\n",
    "        patch_idx = np.random.randint(0, len(predictions))\n",
    "    \n",
    "    # Handle different array shapes\n",
    "    if len(predictions.shape) == 4:  # (batch, channels, height, width)\n",
    "        prediction = predictions[patch_idx, 0]  # Take first channel\n",
    "        binary_prediction = binary_predictions[patch_idx, 0]\n",
    "        target = targets[patch_idx, 0]\n",
    "    elif len(predictions.shape) == 3:  # (batch, height, width)\n",
    "        prediction = predictions[patch_idx]\n",
    "        binary_prediction = binary_predictions[patch_idx]\n",
    "        target = targets[patch_idx]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected prediction shape: {predictions.shape}\")\n",
    "    \n",
    "    return prediction, binary_prediction, target\n",
    "\n",
    "def display_random_patches(num_patches=3):\n",
    "    \"\"\"Display multiple random patches from model predictions.\n",
    "    \n",
    "    Args:\n",
    "        num_patches: Number of patches to display\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If predictions.h5 file doesn't exist\n",
    "        Exception: If there's an error loading predictions\n",
    "    \"\"\"\n",
    "    print(f\"Displaying {num_patches} random patches...\")\n",
    "    \n",
    "    # Load predictions from h5 file\n",
    "    predictions_path = \"../results/predictions.h5\"\n",
    "    try:\n",
    "        predictions, binary_predictions, targets, metadata = load_predictions_from_h5(predictions_path)\n",
    "        print(f\"Successfully loaded predictions from {predictions_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nERROR: Predictions file not found at {predictions_path}\")\n",
    "        print(\"\\nðŸ“‹ To generate predictions, please follow these steps:\")\n",
    "        print(\"   1. Train the model: python main.py\")\n",
    "        print(\"   2. The model will save predictions during evaluation\")\n",
    "        print(\"   3. Re-run this notebook to visualize the predictions\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: {e}\")\n",
    "        print(\"\\nðŸ“‹ Please ensure the predictions file is valid and accessible.\")\n",
    "        return\n",
    "    \n",
    "    for i in range(num_patches):\n",
    "        print(f\"\\n--- Patch {i+1} ---\")\n",
    "        \n",
    "        # Get real patch data\n",
    "        prediction, binary_prediction, target = get_real_patch(\n",
    "            predictions, binary_predictions, targets, patch_idx=None\n",
    "        )\n",
    "        \n",
    "        # Display statistics\n",
    "        patch_height, patch_width = prediction.shape  # type: ignore\n",
    "        total_pixels = patch_height * patch_width\n",
    "        deforestation_area = np.sum(target) / total_pixels * 100  # type: ignore\n",
    "        predicted_area = np.sum(binary_prediction) / total_pixels * 100  # type: ignore\n",
    "        \n",
    "        print(f\"Patch size: {patch_width}x{patch_height}\")\n",
    "        print(f\"Actual deforestation area: {deforestation_area:.2f}%\")\n",
    "        print(f\"Predicted deforestation area: {predicted_area:.2f}%\")\n",
    "        print(f\"Prediction confidence range: [{prediction.min():.3f}, {prediction.max():.3f}]\")  # type: ignore\n",
    "        \n",
    "        # Calculate accuracy metrics\n",
    "        # Calculate IoU (Intersection over Union)\n",
    "        intersection = np.sum((binary_prediction == 1) & (target == 1))\n",
    "        union = np.sum((binary_prediction == 1) | (target == 1))\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = np.sum(binary_prediction == target) / total_pixels\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"IoU: {iou:.3f}\")\n",
    "        \n",
    "        # Plot the patch\n",
    "        plot_prediction_patch(\n",
    "            prediction=prediction,\n",
    "            binary_prediction=binary_prediction,\n",
    "            target=target,\n",
    "            patch_idx=i+1,\n",
    "            figsize=(15, 5),\n",
    "            show=True\n",
    "        )\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display random patches from model predictions\n",
    "display_random_patches(num_patches=4)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Amazon Deforestation Prediction - Model Outputs\n",
    "\n",
    "This notebook displays model predictions for Amazon deforestation using real predictions from `results/predictions.h5`.\n",
    "\n",
    "## Prerequisites:\n",
    "\n",
    "**You must train the model first** to generate the required predictions file:\n",
    "\n",
    "1. Train the model: `python main.py`\n",
    "2. The model will save predictions to `results/predictions.h5` during evaluation\n",
    "3. Run this notebook to visualize the predictions\n",
    "\n",
    "## What this notebook shows:\n",
    "\n",
    "- **Prediction**: Model's confidence scores (0-1) for deforestation\n",
    "- **Binary Prediction**: Thresholded binary mask (deforestation/no deforestation)  \n",
    "- **Target**: Ground truth deforestation mask\n",
    "- **Metrics**: Accuracy, IoU, and area statistics\n",
    "\n",
    "## Error Handling:\n",
    "\n",
    "If the predictions file doesn't exist, the notebook will provide clear instructions on how to generate it by training the model first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-icepred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
